{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44c7f9c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7992dfc",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769bc15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution :\n",
      "label\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: proportion, dtype: float64\n",
      "                                             message  label_num\n",
      "0  Go until jurong point, crazy.. Available only ...          0\n",
      "1                      Ok lar... Joking wif u oni...          0\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
      "3  U dun say so early hor... U c already then say...          0\n",
      "4  Nah I don't think he goes to usf, he lives aro...          0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sms+spam+collection/SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Convert labels to numerical values\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "# Display the distribution of labels\n",
    "print(f\"Original distribution :\\n{df['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "#delete column 'label'\n",
    "df = df.drop(columns=['label'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc96890",
   "metadata": {},
   "source": [
    "### 1. First, set aside a large TEST set (Validation) that we will NEVER touch during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b334d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remaining, X_test, y_remaining, y_test = train_test_split(\n",
    "    df['message'], df['label_num'], test_size=0.2, random_state=42, stratify=df['label_num']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bf7d1",
   "metadata": {},
   "source": [
    "### 2. Now, create a TINY training set from the remaining data\n",
    "Let's say we only want 50 real examples to train on to make it \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18fb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Training Size: 40\n",
      "Test Set Size: 1115\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 40 \n",
    "X_train_real, _, y_train_real, _ = train_test_split(\n",
    "    X_remaining, y_remaining, train_size=TRAIN_SIZE, random_state=42, stratify=y_remaining\n",
    ")\n",
    "\n",
    "print(f\"Real Training Size: {len(X_train_real)}\")\n",
    "print(f\"Test Set Size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b87374",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbbbfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorizer (TF-IDF)\n",
    "# Note: stop_words='english' handles the preprocessing requirement\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit on TRAIN, transform TEST\n",
    "X_train_real_vec = vectorizer.fit_transform(X_train_real)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c2ff9",
   "metadata": {},
   "source": [
    "### Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89de6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chart saved as 'resultat_pca_.png'.\n"
     ]
    }
   ],
   "source": [
    "# 1. FORCER LE MODE SANS ECRAN (Doit être fait avant tout autre import matplotlib)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Force le mode sans interface graphique\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 2. Réduction de dimension (PCA)\n",
    "pca = PCA(n_components=2)\n",
    "# X_train_real_vec est votre matrice TF-IDF issue de l'étape précédente\n",
    "X_reduced = pca.fit_transform(X_train_real_vec.toarray())\n",
    "\n",
    "# 3. Création du graphique\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Scatter plot\n",
    "scatter = plt.scatter(X_reduced[:,0], X_reduced[:,1], \n",
    "                      c=y_train_real, cmap='coolwarm', alpha=0.7, edgecolors='k')\n",
    "\n",
    "plt.title('Visualisation 2D des SMS (PCA)')\n",
    "plt.xlabel('Composante 1')\n",
    "plt.ylabel('Composante 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. SAUVEGARDE (Au lieu de show)\n",
    "# L'image sera enregistrée dans le même dossier que votre script/notebook\n",
    "plt.savefig(\"resultat_pca_.png\")\n",
    "plt.xlim(-0.15, 0.0)\n",
    "plt.ylim(-0.1, 0.1)\n",
    "plt.savefig(\"resultat_pca_focus.png\")\n",
    "print(f\"✅ Chart saved as 'resultat_pca_.png'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657710c",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb2b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       966\n",
      "           1       1.00      0.04      0.08       149\n",
      "\n",
      "    accuracy                           0.87      1115\n",
      "   macro avg       0.94      0.52      0.50      1115\n",
      "weighted avg       0.89      0.87      0.82      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier (SVM is robust for small data)\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train_real_vec, y_train_real)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# Metrics: Use F1-score or MCC because classes are unbalanced!\n",
    "print(\"--- Baseline Results ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "#print(f\"MCC Score: {matthews_corrcoef(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
