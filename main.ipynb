{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44c7f9c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83d853ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Force le mode sans interface graphique\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7992dfc",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769bc15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution :\n",
      "label\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: proportion, dtype: float64\n",
      "                                             message  label_num\n",
      "0  Go until jurong point, crazy.. Available only ...          0\n",
      "1                      Ok lar... Joking wif u oni...          0\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
      "3  U dun say so early hor... U c already then say...          0\n",
      "4  Nah I don't think he goes to usf, he lives aro...          0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sms+spam+collection/SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Convert labels to numerical values\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "# Display the distribution of labels\n",
    "print(f\"Original distribution :\\n{df['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "#delete column 'label'\n",
    "df = df.drop(columns=['label'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7a4bc",
   "metadata": {},
   "source": [
    "Show raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1da1b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['message'])\n",
    "y = df['label_num']\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "\n",
    "#chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_reduced[:,0], X_reduced[:,1], \n",
    "                      c=y, cmap='coolwarm', alpha=0.3, edgecolors='k')\n",
    "\n",
    "# legend\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, ['0 (Ham)', '1 (Spam)'], title=\"Classes\")\n",
    "\n",
    "plt.title('2D PCA of SMS Spam Collection Dataset')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(\"charts/resultat_full_data.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc96890",
   "metadata": {},
   "source": [
    "### 1. First, set aside a large TEST set (Validation) that we will NEVER touch during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69b334d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_remaining, X_test, y_remaining, y_test = train_test_split(\n",
    "    df['message'], df['label_num'], test_size=0.2, random_state=42, stratify=df['label_num']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bf7d1",
   "metadata": {},
   "source": [
    "### 2. Now, create a TINY training set from the remaining data\n",
    "Let's say we only want 50 real examples to train on to make it \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18fb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Training Size: 40\n",
      "Test Set Size: 1115\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 40 \n",
    "X_train_real, _, y_train_real, _ = train_test_split(\n",
    "    X_remaining, y_remaining, train_size=TRAIN_SIZE, random_state=42, stratify=y_remaining\n",
    ")\n",
    "\n",
    "print(f\"Real Training Size: {len(X_train_real)}\")\n",
    "print(f\"Test Set Size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b87374",
   "metadata": {},
   "source": [
    "### 3. Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbbbfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorizer (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit on TRAIN, transform TEST\n",
    "X_train_real_vec = vectorizer.fit_transform(X_train_real)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c2ff9",
   "metadata": {},
   "source": [
    "### Plot training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA reduction to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X_train_real_vec.toarray())\n",
    "\n",
    "# chart\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_reduced[:,0], X_reduced[:,1], \n",
    "                      c=y_train_real, cmap='coolwarm', alpha=0.7, edgecolors='k')\n",
    "plt.title('2D PCA of Real Training Data (40 samples)')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# legend\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, ['0 (Ham)', '1 (Spam)'], title=\"Classes\")\n",
    "\n",
    "# save chart\n",
    "plt.savefig(\"charts/resultat_reduced_data.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657710c",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb2b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       966\n",
      "           1       1.00      0.04      0.08       149\n",
      "\n",
      "    accuracy                           0.87      1115\n",
      "   macro avg       0.94      0.52      0.50      1115\n",
      "weighted avg       0.89      0.87      0.82      1115\n",
      "\n",
      "MCC Score: 0.18728598572773505\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier (SVM is robust for small data)\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train_real_vec, y_train_real)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# Metrics: Use F1-score or MCC because classes are unbalanced!\n",
    "print(\"--- Baseline Results ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"MCC Score: {matthews_corrcoef(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2f7df",
   "metadata": {},
   "source": [
    "### Matrice de confusion (SVM Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7f7f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm_display = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues')\n",
    "cm_display.figure_.savefig(\"charts/confusion_matrix_reduced_data.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f9465",
   "metadata": {},
   "source": [
    "### SVM Classifier with kernel trick\n",
    "The RBF kernel tries to draw complex \"bubbles\" around data points. With so few Spam examples in your tiny training set (maybe 3 or 4), the SVM likely created tiny bubbles around them that were too specific (overfitting), or it simply ignored them to minimize the global error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e755906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       966\n",
      "           1       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.87      1115\n",
      "   macro avg       0.43      0.50      0.46      1115\n",
      "weighted avg       0.75      0.87      0.80      1115\n",
      "\n",
      "MCC Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titmo/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/titmo/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/titmo/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train Classifier (SVM is robust for small data)\n",
    "clf_rbf = SVC(kernel='rbf', C=1000, gamma='scale')\n",
    "clf_rbf.fit(X_train_real_vec, y_train_real)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rbf = clf_rbf.predict(X_test_vec)\n",
    "\n",
    "# Metrics: Use F1-score or MCC because classes are unbalanced!\n",
    "print(\"--- Baseline Results ---\")\n",
    "print(classification_report(y_test, y_pred_rbf))\n",
    "print(f\"MCC Score: {matthews_corrcoef(y_test, y_pred_rbf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c77f7",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ef16d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data size : 70\n",
      "New training set size : 110\n"
     ]
    }
   ],
   "source": [
    "# Example spam messages for data augmentation generate with Gemini\n",
    "synthetic_spams = [\n",
    "    \"URGENT: You have an unclaimed PPI refund of £3,850 waiting for you! Reply CLAIM to 07890123456 immediately to verify your details.\",\n",
    "    \"CONGRATS! You've been selected for a £1000 Tesco gift card. Press 1 or go to http://www.winner-uk-prizes.com/claim now! Offer ends 2mrw.\",\n",
    "    \"WARNING: We have detected unusual activity on your Santander account. Please log in at http://secure-santander-update.com to verify your identity.\",\n",
    "    \"Hey hun, saw your profile online ;) I'm lonely tonight. Text CHAT to 69888 to connect with singles in your area. 18+ only. £1.50/msg.\",\n",
    "    \"FINAL NOTICE: HMRC has issued a tax refund of £465.80. You must claim by Friday or funds will be returned. Visit http://hmrc-gov-refunds.co.uk\",\n",
    "    \"You have won a FREE iPhone 15 Pro! Reply YES to +447700900123 to arrange delivery. T&Cs apply.\",\n",
    "    \"Your package from Royal Mail is held at the depot due to unpaid shipping fee of £2.99. Pay now at: http://royal-mail-fee-pay.com to avoid return.\",\n",
    "    \"LOAN APPROVED: You are eligible for an unsecured loan of up to £5000. No credit check required. Text CASH to 80099.\",\n",
    "    \"Hi, is this John? I found your number in my old phone. Want to meet up? check my pics at http://bit.ly/sexy-pics-uk\",\n",
    "    \"NATWEST ALERT: A new payee was added to your account on 26/12. If this wasn't you, click here immediately: http://natwest-security-check.net\",\n",
    "    \"IMPORTANT: Our records show you were involved in a non-fault accident. You could be owed up to £2500. Reply CLAIM to proceed.\",\n",
    "    \"PRIVATE! Your 2000 bonus points expire in 24 hours. Redeem for cash or vouchers at http://redeem-points-now.co.uk\",\n",
    "    \"Someone special wants to meet you! Find out who it is by replying LOVE to 85555. texts cost £2.\",\n",
    "    \"URGENT! Your mobile number was chosen as the WINNER of our daily lottery! Claim your £500,000 prize. Call 09066612345 NOW!\",\n",
    "    \"Barclays: Your debit card starting 4855 has been temporarily suspended due to suspicious transaction. Reactivate: http://barclays-auth-id.com\",\n",
    "    \"FREE ENTRY to our £200 weekly draw! Just text WIN to 82228. 16+ only. Help? 0800123456\",\n",
    "    \"Reminder: You have a new voicemail from 07812345678. Listen now at http://vmail-box.co.uk/listen\",\n",
    "    \"Hot local girls want to chat! Don't be shy. Text DATE to 66777. 1st msg FREE.\",\n",
    "    \"AMAZON: Your order #445-1234 is pending delivery. confirm your address to receive it tomorrow: http://amzn-delivery-update.co.uk\",\n",
    "    \"URGENT ALERT: Your energy bill is overdue by £145. Power will be disconnected in 24hrs. Pay here: http://british-gas-pay.com\",\n",
    "    \"YOU WON! A holiday to Ibiza for 2 people is waiting for you! Call +447000123456 to book your dates.\",\n",
    "    \"HSBC: Did you attempt a payment of £1200 to 'Argos'? Reply Y if yes or N if no. If N, follow link: http://hsbc-fraud-team.com\",\n",
    "    \"LUCKY DAY! You have been selected for a £500 ASDA voucher. Click to claim: http://asda-rewards-uk.com\",\n",
    "    \"Need cash fast? Get up to £1000 in your bank within 15 mins! Text LOAN to 88990. 1289% APR Rep.\",\n",
    "    \"Hey! I saw you at the pub last night but was too shy to say hi. Text me back? xoxo 07999888777\",\n",
    "    \"CRITICAL: We have been trying to contact you about your car insurance claim. You are due £1,230. Reply INFO now.\",\n",
    "    \"Congratulations! Your mobile number won the UK Lotto. Prize: £1,000,000. Email claims@uk-lotto-winners.com with code UK55.\",\n",
    "    \"DPD: We missed you today. Your parcel is at the depot. Reschedule delivery here: http://dpd-missed-parcel.com\",\n",
    "    \"Last chance to claim your £150 Amazon Gift Card! Survey expires in 2 hours. Go to http://survey-rewards.co.uk\",\n",
    "    \"HALIFAX SECURITY: Unusual login attempt from IP 192.168.0.1. Account locked. Unlock here: http://halifax-verify-user.com\",\n",
    "    \"Are you single? Join the UK's hottest dating site for FREE today. Click http://uk-singles-meet.com\",\n",
    "    \"YOU HAVE 1 NEW MESSAGE. A secret admirer left a recording. Call 09050001234 to listen. £1.50/min.\",\n",
    "    \"URGENT: Your vehicle tax is expired. You will be fined £1000 if not paid by tomorrow. Renew at http://dvla-gov-tax.co.uk\",\n",
    "    \"Mystery Shopper needed! Earn £300/week evaluating local shops. Apply now: http://mystery-jobs-uk.com\",\n",
    "    \"Lloyds Bank: Payment to AIRBNB for £450.00 declined. If this was not you, visit http://lloyds-fraud-prevention.com\",\n",
    "    \"Double your data for free! Offer ends midnight. Reply YES to activate. O2 Rewards.\",\n",
    "    \"WINNER!! You have won a luxury cruise to the Caribbean! Text CRUISE to 80022 to claim. T&C Apply.\",\n",
    "    \"Hi its Sarah. My phone broke so I'm using this number. Msg me back on WhatsApp +447555123456 urgent.\",\n",
    "    \"Alert: You have been exposed to someone who tested positive for COVID-19. Order a test kit: http://nhs-test-trace-uk.com\",\n",
    "    \"Exclusive deal! 70% off Ray-Ban sunglasses. Today only. Shop now: http://rayban-outlet-sale.co.uk\",\n",
    "    \"WARNING: Your Apple ID has been locked due to security reasons. Verify your identity at http://apple-id-recover-uk.com\",\n",
    "    \"Naughty girls waiting for your call... don't make them wait! Call 09099998888. £2/min.\",\n",
    "    \"EE: Your bill for this month is £125.40. This is higher than usual. View details: http://my-ee-bill-check.com\",\n",
    "    \"Did you have an accident that wasn't your fault? You could claim thousands! No win no fee. Text ACCIDENT to 77888.\",\n",
    "    \"CONGRATS! You are the 1000th visitor! Claim your prize: iPad Air 2. Click http://apple-rewards.com\",\n",
    "    \"Netflix: Your subscription payment failed. Update payment details to avoid suspension: http://netflix-account-update.com\",\n",
    "    \"URGENT!!! Your bank account is frozen due to missing information. Visit your local branch or click http://bank-verify.co.uk\",\n",
    "    \"Hot mums in your area want casual fun! No strings attached. Text MUM to 69000. 18+.\",\n",
    "    \"SKY: Your broadband service will be terminated tomorrow due to non-payment. Pay £45.99 now: http://sky-bill-pay.com\",\n",
    "    \"FINAL WARNING: You have 1 unclaimed reward of £500. It expires in 30 mins. Claim here: http://claim-funds-fast.co.uk\"\n",
    "]\n",
    "\n",
    "synthetic_hams = [\n",
    "    \"Hey u coming to the library? im on the 3rd floor by the quiet zone.\",\n",
    "    \"Starving rn. wanna grab lunch at the su in like 20 mins?\",\n",
    "    \"did u finish the assignment for prof smith? im so confused lol\",\n",
    "    \"Where r u?? lecture starts in 5 mins run!!\",\n",
    "    \"meet me at starbucks b4 seminar, need coffee badly.\",\n",
    "    \"Can i borrow ur notes from yesterday? i totally zoned out.\",\n",
    "    \"im gonna be late, bus is taking forever. save me a seat pls.\",\n",
    "    \"Are we still on for study group 2mrw or nah?\",\n",
    "    \"Library is absolute chaos rn, no seats anywhere :/\",\n",
    "    \"u wanna get pizza tonight? cba to cook.\",\n",
    "    \"Just sent u the draft, let me know if it looks ok.\",\n",
    "    \"omg i forgot we had a quiz today. im dead.\",\n",
    "    \"Wait is the deadline tonight or 2mrw?? panic checking.\",\n",
    "    \"Meeting sarah at the pub later if u wanna join.\",\n",
    "    \"Done with class finally. u still on campus?\",\n",
    "    \"Check ur email, the tutor just cancelled the 9am lecture!!!\",\n",
    "    \"cant make it to lunch sorry, gotta finish this essay.\",\n",
    "    \"Whats the room number again? im lost in the new building.\",\n",
    "    \"bringing snacks to the library, text me if u want anything.\",\n",
    "    \"seriously where are u guys? ive been waiting for 15 mins.\"\n",
    "]\n",
    "\n",
    "# Create synthetic dataframe\n",
    "# Label 1 = Spam, Label 0 = Ham\n",
    "df_synthetic = pd.DataFrame({\n",
    "    'message': synthetic_spams + synthetic_hams,\n",
    "    'label_num': [1] * len(synthetic_spams) + [0] * len(synthetic_hams)\n",
    "})\n",
    "\n",
    "print(f\"Generated synthetic data size : {len(df_synthetic)}\")\n",
    "\n",
    "# Merge the datasets (Real Train + Synthetic)\n",
    "X_train_aug = pd.concat([X_train_real, df_synthetic['message']])\n",
    "y_train_aug = pd.concat([y_train_real, df_synthetic['label_num']])\n",
    "print(f\"New training set size : {len(X_train_aug)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec397267",
   "metadata": {},
   "source": [
    "### Training the Augmented SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6e44910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULTS WITH LLM AUGMENTATION ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       966\n",
      "           1       0.62      0.91      0.74       149\n",
      "\n",
      "    accuracy                           0.91      1115\n",
      "   macro avg       0.80      0.91      0.84      1115\n",
      "weighted avg       0.94      0.91      0.92      1115\n",
      "\n",
      "New MCC Score: 0.7060430306112683\n"
     ]
    }
   ],
   "source": [
    "# Re-Vectorization\n",
    "# We relearn the vocabulary on the augmented set\n",
    "vectorizer_aug = TfidfVectorizer(stop_words='english')\n",
    "X_train_aug_vec = vectorizer_aug.fit_transform(X_train_aug)\n",
    "\n",
    "# IMPORTANT : We transform X_test with this NEW vectorizer\n",
    "X_test_aug_vec = vectorizer_aug.transform(X_test)\n",
    "\n",
    "# 3. Training the Augmented SVM\n",
    "clf_aug = SVC(kernel='linear') \n",
    "clf_aug.fit(X_train_aug_vec, y_train_aug)\n",
    "\n",
    "# 4. Evaluation\n",
    "y_pred_aug = clf_aug.predict(X_test_aug_vec)\n",
    "\n",
    "print(\"--- RESULTS WITH LLM AUGMENTATION ---\")\n",
    "print(classification_report(y_test, y_pred_aug))\n",
    "print(f\"New MCC Score: {matthews_corrcoef(y_test, y_pred_aug)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
